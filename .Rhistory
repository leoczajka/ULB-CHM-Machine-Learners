rm(list = ls())
if (Sys.info()[8] == "leoczajka") {
setwd("/Users/leoczajka/Dropbox (Leo_and_Co)/Research/learning/Doctoral Training/machine-learning/ULB-CHM-Machine-Learners")
}
if (Sys.info()[8] == "??") {
setwd("~/BioInformatique/MA1/Q2/machine learning/projet")
}
if (Sys.info()[8] == "??") {
setwd("~/RProjects/Pumpit")
}
# load packages
library(Hmisc)
library(tidyverse)
library(dplyr)
library(caret)
library(xgboost)
# running time is extremely slow so we will restrict our sample
# keep var with
# common mistakes : "factor quantity has new levels unknown"
df_gbt <- df %>% filter(df$construction_year!=0)
df_gbt <- df_gbt %>% filter(df_gbt$population>1)
df_gbt <- df_gbt %>% filter(df_gbt$amount_tsh>0)
df_gbt$random_100 <- runif(nrow(df_gbt), min=1, max=nrow(df_gbt))
df_gbt$subset_100 <-  ntile(df_gbt$random_100, 100)
df_gbt <- df_gbt %>% filter(df_gbt$subset_100 < 6)
nrow(df_gbt)
df_gbt$random <- runif(nrow(df_gbt), min=1, max=nrow(df_gbt))
df_gbt$subset <-  ntile(df_gbt$random, 10)
gbt_model_1 <- function(some_number) {
df_train <- df_gbt %>% filter(df_gbt$subset == some_number)
df_test <- df_gbt %>% filter(df_gbt$subset != some_number)
model_gbt <- train(as.factor(status_group) ~
+ gps_height + population
+ construction_year + longitude + quantity + latitude,
data = df_train,
method = "xgbTree")
df_test$y_pred <- predict(model_gbt, df_test)
error <- sum(df_test$y_pred!=df_test$status_group)/nrow(df_test)
results <- list("df_test" = df_test , "model_gbt" = model_gbt, "error" = error)
return(results)
}
list_results <- lapply(1:10, gbt_model_1) #Generate data
for (i in 1:10){
print(list_results[[i]][3]$error)
}
rm(list = ls())
if (Sys.info()[8] == "leoczajka") {
setwd("/Users/leoczajka/Dropbox (Leo_and_Co)/Research/learning/Doctoral Training/machine-learning/ULB-CHM-Machine-Learners")
}
if (Sys.info()[8] == "??") {
setwd("~/BioInformatique/MA1/Q2/machine learning/projet")
}
if (Sys.info()[8] == "??") {
setwd("~/RProjects/Pumpit")
}
# load packages
library(Hmisc)
library(tidyverse)
library(dplyr)
library(caret)
library(xgboost)
# Importing data sets
train_values <- read.csv("trainingsetvalues.csv")
train_labels <- read.csv("trainingsetlabels.csv")
df <- merge(train_values, train_labels)
test_values <- read.csv("testsetvalues.csv")
# Elements of strategy
# start with the simplest model - without all hard to deal with data
# make a data set with missing values
# make a data set with replaced missing values
# for cat-var = set missing to some cat
# for num var - either remove the var or set to missing (remove data), or set to the mode/mean or P50
# remove var with too many weird values
# always remove unprecise small cat
# add very precise cat-var progressively
# general cleaning : set categorical var into factor
# classify the variables based on type and number of different values
# get a glimpse at the data
describe(df)
# irrelevant or not varying variables
# num_private, recorded_by
# numerical variables
# amount_tsh - but few values - 98, many 0
# gps_height - half are 0
# longitude
# latitude
# population - many 0
hist(df$latitude)
hist(df$longitude) # set 0 to Mode ? set NA
hist(df$population[df$population>1 & df$population <500]) #
table(df$population) # put at test
# unlikely counts for 0 and 1 - set to NA - set to mode or P50
hist(df$gps_height)
hist(df$amount_tsh[df$amount_tsh>0 & df$amount_tsh<1000])
table(df$amount_tsh) # pretty weird values
# categorical var
# FEW
# basin - 9
table(df$basin)
# region - 21
table(df$region)
# region_code  27
table(df$region_code)
table(df$region_code, df$region) # to be tested
# district_code - 20
table(df$district_code)
# lga - 125
table(df$lga)
ggplot(df) + geom_bar(aes(x = lga))
# public_meeting - 2
table(df$public_meeting)
# scheme_management 12
table(df$scheme_management)
# permit  2 - 3056
table(df$permit)
# construction_year  - 55
hist(df$construction_year[df$construction_year!=0])
# to be tested
# extraction_type - 18 extraction_type_group extraction_type_class
table(df$extraction_type, df$extraction_type_group)
table(df$extraction_type_group, df$extraction_type_class)
# management management_group
table(df$management, df$management_group )
# payment payment_type
table(df$payment,df$payment_type )
# water_quality quality_group
table(df$water_quality,df$quality_group )
# quantity quantity_group
table(df$quantity, df$quantity_group)
# source source_type source_class
table(df$source, df$source_type )
table(df$source_type,df$source_class )
# waterpoint_type waterpoint_type_group
table(df$waterpoint_type,df$waterpoint_type_group )
# NUMEROUS
# date_recorded - 356 different values - can be transformed into
ggplot(df) + geom_bar(aes(x = date_recorded))
df$m_date <- as.Date(df$date_recorded)
df$daily_time_trend <- as.numeric(df$m_date) # remove the too early ones
hist(df$daily_time_trend[df$daily_time_trend>14942], breaks = seq(from=14942, to=16042, by=10))
df$m_year <- as.numeric(format(df$m_date,'%Y'))
df$m_months <- as.numeric(format(df$m_date,'%m'))
df$m_day <- weekdays(df$m_date)
df$time <- df$m_year - df$construction_year
df$time[df$construction_year==0] <- NA # to b tested
# View(df %>% filter(df$time==53))
ggplot(df) + geom_bar(aes(x = m_day))
ggplot(df) + geom_bar(aes(x = m_months))
# ward - 2092
# ggplot(df) + geom_bar(aes(x = ward))
# funder -  1897  distinct - 3635 missing
# installer - 2145
# wpt_name 37400
# subvillage 19287
# scheme_name  - 2696
df$installer <- tolower(df$installer)
df$funder <- tolower(df$funder)
df$wpt_name <- tolower(df$wpt_name)
df$subvillage <- tolower(df$subvillage)
df$scheme_name <- tolower(df$scheme_name)
table(df$funder)
df$funder_is_installer <- df$funder == df$installer & df$installer!=""
df$funder_is_installer[df$installer=="" | df$funder==""] <- NA
table(df$funder_is_installer)
# create variables :
# distance to measuring dates
# year and month of the measured
df<- df[, !(colnames(df) %in% c("region", "extraction_type_group", "extraction_type_class", "management_group", "payment_type", "quality_group", "quantity_group", "source_class","source_type", "waterpoint_type_group", "num_private", "recorded_by"))]
# remove also the date - better use it as numerical
str(df)
# so what do we get for the most basic model?
# running time is extremely slow so we will restrict our sample
# keep var with
# common mistakes : "factor quantity has new levels unknown"
df_gbt <- df %>% filter(df$construction_year!=0)
df_gbt <- df_gbt %>% filter(df_gbt$population>1)
df_gbt <- df_gbt %>% filter(df_gbt$amount_tsh>0)
df_gbt$random_100 <- runif(nrow(df_gbt), min=1, max=nrow(df_gbt))
df_gbt$subset_100 <-  ntile(df_gbt$random_100, 100)
df_gbt <- df_gbt %>% filter(df_gbt$subset_100 < 6)
nrow(df_gbt)
df_gbt$random <- runif(nrow(df_gbt), min=1, max=nrow(df_gbt))
df_gbt$subset <-  ntile(df_gbt$random, 10)
gbt_model_1 <- function(some_number) {
df_train <- df_gbt %>% filter(df_gbt$subset == some_number)
df_test <- df_gbt %>% filter(df_gbt$subset != some_number)
model_gbt <- train(as.factor(status_group) ~
+ gps_height + population
+ construction_year + longitude + quantity + latitude,
data = df_train,
method = "xgbTree")
df_test$y_pred <- predict(model_gbt, df_test)
error <- sum(df_test$y_pred!=df_test$status_group)/nrow(df_test)
results <- list("df_test" = df_test , "model_gbt" = model_gbt, "error" = error)
return(results)
}
list_results <- lapply(1:10, gbt_model_1) #Generate data
for (i in 1:10){
print(list_results[[i]][3]$error)
}
# running time is extremely slow so we will restrict our sample
# keep var with
# common mistakes : "factor quantity has new levels unknown"
df_gbt <- df %>% filter(df$construction_year!=0)
df_gbt <- df_gbt %>% filter(df_gbt$population>1)
df_gbt <- df_gbt %>% filter(df_gbt$amount_tsh>0)
df_gbt$random_100 <- runif(nrow(df_gbt), min=1, max=nrow(df_gbt))
df_gbt$subset_100 <-  ntile(df_gbt$random_100, 100)
df_gbt <- df_gbt %>% filter(df_gbt$subset_100 < 10)
nrow(df_gbt)
df_gbt$random <- runif(nrow(df_gbt), min=1, max=nrow(df_gbt))
df_gbt$subset <-  ntile(df_gbt$random, 10)
gbt_model_1 <- function(some_number) {
df_train <- df_gbt %>% filter(df_gbt$subset == some_number)
df_test <- df_gbt %>% filter(df_gbt$subset != some_number)
model_gbt <- train(as.factor(status_group) ~
+ gps_height + population
+ construction_year + longitude + quantity + latitude,
data = df_train,
method = "xgbTree")
df_test$y_pred <- predict(model_gbt, df_test)
error <- sum(df_test$y_pred!=df_test$status_group)/nrow(df_test)
results <- list("df_test" = df_test , "model_gbt" = model_gbt, "error" = error)
return(results)
}
list_results <- lapply(1:10, gbt_model_1) #Generate data
for (i in 1:10){
print(list_results[[i]][3]$error)
}
# running time is extremely slow so we will restrict our sample
# keep var with
# common mistakes : "factor quantity has new levels unknown"
df_gbt <- df %>% filter(df$construction_year!=0)
df_gbt <- df_gbt %>% filter(df_gbt$population>1)
df_gbt <- df_gbt %>% filter(df_gbt$amount_tsh>0)
df_gbt$random_100 <- runif(nrow(df_gbt), min=1, max=nrow(df_gbt))
df_gbt$subset_100 <-  ntile(df_gbt$random_100, 100)
df_gbt <- df_gbt %>% filter(df_gbt$subset_100 < 10)
nrow(df_gbt)
df_gbt$random <- runif(nrow(df_gbt), min=1, max=nrow(df_gbt))
df_gbt$subset <-  ntile(df_gbt$random, 10)
gbt_model_1 <- function(some_number) {
df_train <- df_gbt %>% filter(df_gbt$subset == some_number)
df_test <- df_gbt %>% filter(df_gbt$subset != some_number)
model_gbt <- train(as.factor(status_group) ~
+ gps_height + population
+ construction_year + longitude + quantity_group + latitude,
data = df_train,
method = "xgbTree")
df_test$y_pred <- predict(model_gbt, df_test)
error <- sum(df_test$y_pred!=df_test$status_group)/nrow(df_test)
results <- list("df_test" = df_test , "model_gbt" = model_gbt, "error" = error)
return(results)
}
list_results <- lapply(1:10, gbt_model_1) #Generate data
for (i in 1:10){
print(list_results[[i]][3]$error)
}
rm(list = ls())
if (Sys.info()[8] == "leoczajka") {
setwd("/Users/leoczajka/Dropbox (Leo_and_Co)/Research/learning/Doctoral Training/machine-learning/ULB-CHM-Machine-Learners")
}
if (Sys.info()[8] == "??") {
setwd("~/BioInformatique/MA1/Q2/machine learning/projet")
}
if (Sys.info()[8] == "??") {
setwd("~/RProjects/Pumpit")
}
# load packages
library(Hmisc)
library(tidyverse)
library(dplyr)
library(caret)
library(xgboost)
# Importing data sets
train_values <- read.csv("trainingsetvalues.csv")
train_labels <- read.csv("trainingsetlabels.csv")
df <- merge(train_values, train_labels)
test_values <- read.csv("testsetvalues.csv")
# Elements of strategy
# start with the simplest model - without all hard to deal with data
# make a data set with missing values
# make a data set with replaced missing values
# for cat-var = set missing to some cat
# for num var - either remove the var or set to missing (remove data), or set to the mode/mean or P50
# remove var with too many weird values
# always remove unprecise small cat
# add very precise cat-var progressively
# general cleaning : set categorical var into factor
# classify the variables based on type and number of different values
# get a glimpse at the data
describe(df)
describe(df$num_private)
describe(df$recorded_by)
hist(df$gps_height)
table(df$gps_height)
hist(df$latitude)
hist(df$longitude) # set 0 to Mode ? set NA
table(df$longitude)
nrow(df$longitude==0)
sum(df$longitude==0)
sum(df$gps_height==0)
sum(df$latitude==0)
hist(df$latitude)
sum(df$latitude>0)
sum(df$latitude<0)
1812/59400
hist(df$population[df$population>1 & df$population <500]) #
table(df$population)
sum(df$population==0)/nrow(df)
sum(df$population==1)/nrow(df)
version
hist(df$population[df$population>1 & df$population <500])
hist(df$population)
hist(df$amount_tsh)
sum(df$amount_tsh==0)/nrow(df)
hist(df$amount_tsh[df$amount_tsh>0])
hist(df$amount_tsh[df$amount_tsh>0 & df$amount_ts <500])
hist(df$amount_tsh[df$amount_tsh>0 & df$amount_ts <50])
hist(df$amount_tsh[df$amount_tsh>0 & df$amount_ts <5000])
hist(df$amount_tsh[df$amount_tsh>0 & df$amount_ts <500])
sum(df$amount_tsh==0)/nrow(df)
hist(df$amount_tsh[df$amount_tsh>0 & df$amount_ts <5])
hist(df$amount_tsh[df$amount_tsh>0 & df$amount_ts <50])
hist(df$amount_tsh[df$amount_tsh>0 & df$amount_ts <500], breaks = seq(from=1, to=500, by=10))
hist(df$amount_tsh[df$amount_tsh>0 & df$amount_ts <500], breaks = seq(from=1, to=501, by=10))
hist(df$amount_tsh[df$amount_tsh>0 & df$amount_ts <502], breaks = seq(from=1, to=501, by=10))
hist(df$amount_tsh[df$amount_tsh>0 & df$amount_tsh<1000])
hist(df$population[df$population>1 & df$population <500])
hist(df$population[df$population>1 & df$population <500], breaks = seq(from=1, to=500, by=10))
hist(df$population[df$population>1 & df$population <500], breaks = seq(from=1, to=501, by=10))
table(df$status_group)
df$m_date <- as.Date(df$date_recorded)
hist(df$m_date)
hist(df$daily_time_trend)
df$daily_time_trend <- as.numeric(df$m_date) # remove the too early ones
hist(df$daily_time_trend)
table(df$daily_time_trend)
df <- df %>% filter(df$daily_time_trend<14977)
nrow(df$daily_time_trend)
rm(list = ls())
if (Sys.info()[8] == "leoczajka") {
setwd("/Users/leoczajka/Dropbox (Leo_and_Co)/Research/learning/Doctoral Training/machine-learning/ULB-CHM-Machine-Learners")
}
if (Sys.info()[8] == "??") {
setwd("~/BioInformatique/MA1/Q2/machine learning/projet")
}
if (Sys.info()[8] == "??") {
setwd("~/RProjects/Pumpit")
}
# load packages
library(Hmisc)
library(tidyverse)
library(dplyr)
library(caret)
library(xgboost)
# Importing data sets
train_values <- read.csv("trainingsetvalues.csv")
train_labels <- read.csv("trainingsetlabels.csv")
df <- merge(train_values, train_labels)
test_values <- read.csv("testsetvalues.csv")
# Elements of strategy
# start with the simplest model - without all hard to deal with data
# make a data set with missing values
# make a data set with replaced missing values
# for cat-var = set missing to some cat
# for num var - either remove the var or set to missing (remove data), or set to the mode/mean or P50
# remove var with too many weird values
# always remove unprecise small cat
# add very precise cat-var progressively
# general cleaning : set categorical var into factor
# classify the variables based on type and number of different values
# get a glimpse at the data
describe(df)
# irrelevant or not varying variables
# num_private, recorded_by
describe(df$num_private)
describe(df$recorded_by)
# numerical variables
# amount_tsh - but few values - 98, many 0
# gps_height - half are 0
# longitude
# latitude
# population - many 0
hist(df$latitude)
sum(df$latitude==0)
hist(df$longitude) # set 0 to Mode ? set NA
sum(df$longitude==0)
hist(df$gps_height)
sum(df$gps_height==0)
df<- df[, !(colnames(df) %in% c("num_private", "recorded_by"))]
table(df$population)
hist(df$population[df$population>1 & df$population <500]) #
# put at test
# unlikely counts for 0 and 1 - set to NA - set to mode or P50
hist(df$amount_tsh[df$amount_tsh>0 & df$amount_tsh<1000])
table(df$amount_tsh) # pretty weird values
# categorical var
# FEW
# basin - 9
table(df$basin)
# region - 21
table(df$region)
# region_code  27
table(df$region_code)
table(df$region_code, df$region) # to be tested
# district_code - 20
table(df$district_code)
# lga - 125
table(df$lga)
ggplot(df) + geom_bar(aes(x = lga))
# public_meeting - 2
table(df$public_meeting)
# scheme_management 12
table(df$scheme_management)
# permit  2 - 3056
table(df$permit)
# construction_year  - 55
hist(df$construction_year[df$construction_year!=0])
# to be tested
# extraction_type - 18 extraction_type_group extraction_type_class
table(df$extraction_type, df$extraction_type_group)
table(df$extraction_type_group, df$extraction_type_class)
# management management_group
table(df$management, df$management_group )
# payment payment_type
table(df$payment,df$payment_type )
# water_quality quality_group
table(df$water_quality,df$quality_group )
# quantity quantity_group
table(df$quantity, df$quantity_group)
# source source_type source_class
table(df$source, df$source_type )
table(df$source_type,df$source_class )
# waterpoint_type waterpoint_type_group
table(df$waterpoint_type,df$waterpoint_type_group )
# NUMEROUS
# date_recorded - 356 different values - can be transformed into
ggplot(df) + geom_bar(aes(x = date_recorded))
df$m_date <- as.Date(df$date_recorded)
df$daily_time_trend <- as.numeric(df$m_date) # remove the too early ones
hist(df$daily_time_trend[df$daily_time_trend>14942], breaks = seq(from=14942, to=16042, by=10))
df$m_year <- as.numeric(format(df$m_date,'%Y'))
df$m_months <- as.numeric(format(df$m_date,'%m'))
df$m_day <- weekdays(df$m_date)
df$time <- df$m_year - df$construction_year
df$time[df$construction_year==0] <- NA # to b tested
# View(df %>% filter(df$time==53))
ggplot(df) + geom_bar(aes(x = m_day))
ggplot(df) + geom_bar(aes(x = m_months))
# ward - 2092
# ggplot(df) + geom_bar(aes(x = ward))
# funder -  1897  distinct - 3635 missing
# installer - 2145
# wpt_name 37400
# subvillage 19287
# scheme_name  - 2696
df$installer <- tolower(df$installer)
df$funder <- tolower(df$funder)
df$wpt_name <- tolower(df$wpt_name)
df$subvillage <- tolower(df$subvillage)
df$scheme_name <- tolower(df$scheme_name)
table(df$funder)
df$funder_is_installer <- df$funder == df$installer & df$installer!=""
df$funder_is_installer[df$installer=="" | df$funder==""] <- NA
table(df$funder_is_installer)
# create variables :
# distance to measuring dates
# year and month of the measured
df<- df[, !(colnames(df) %in% c("region", "extraction_type_group", "extraction_type_class", "management_group", "payment_type", "quality_group", "quantity_group", "source_class","source_type", "waterpoint_type_group", "num_private", "recorded_by"))]
# remove also the date - better use it as numerical
str(df)
# so what do we get for the most basic model?
table(df$public_meeting)
table(df$public_meeting, df$status_group)
table(df$scheme_management)
df$time
hist(df$construction_year[df$construction_year!=0])
table(df$df$funder_is_installer)
table(df$funder_is_installer)
library(mlbench)# For data
library(FSelector)
install.packages('FSelector')
chi.squared(status_group~., df)
library(FSelector)
library(FSelector)
hist(df$daily_time_trend[df$daily_time_trend>14942], breaks = seq(from=14942, to=16042, by=10))
df$m_year <- as.factor(as.numeric(format(df$m_date,'%Y')))
sum(df$construction_year==0)/nrow(df)
describe(df$construction_year[df$construction_year!=0])
df$construction_year[df$construction_year==0] <- 2000
describe(df$construction_year[df$construction_year!=0])
df$funder_is_installer <- df$funder == df$installer & df$installer!=""
df$funder_is_installer[df$installer=="" | df$funder==""] <- "MISSING"
table(df$funder_is_installer)
rf_model_1 <- function(some_number, number_of_tree) {
df_train <- train %>% filter(train$subset == some_number)
df_test <- train %>% filter(train$subset != some_number)
model_forest <- randomForest(as.factor(status_group) ~
+ gps_height  + date_recorded
+ longitude + latitude + management
+ extraction_type_group
+ water_quality + quantity + source
+ waterpoint_type ,
data = df_train,
ntree = number_of_tree, nodesize = 2)
df_test$y_pred <- predict(model_forest, df_test)
error <- sum(df_test$y_pred!=df_test$status_group)/nrow(df_test)
results <- list("df_test" = df_test , "model_forest" = model_forest, "error" = error)
return(results)
}
list_results <- lapply(1:2, lapply(70:72,rf_model_1)) #Generate data
